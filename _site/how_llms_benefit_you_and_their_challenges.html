<!DOCTYPE html>

<html lang="en-US">

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width,maximum-scale=2">
    <link rel="stylesheet" href="/Study-Site/assets/css/styles.css">

    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>How LLMs Benefit You and Their Challenges | A Study on LLMs</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="How LLMs Benefit You and Their Challenges" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://localhost:4000/Study-Site/how_llms_benefit_you_and_their_challenges.html" />
<meta property="og:url" content="http://localhost:4000/Study-Site/how_llms_benefit_you_and_their_challenges.html" />
<meta property="og:site_name" content="A Study on LLMs" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="How LLMs Benefit You and Their Challenges" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","headline":"How LLMs Benefit You and Their Challenges","url":"http://localhost:4000/Study-Site/how_llms_benefit_you_and_their_challenges.html"}</script>
<!-- End Jekyll SEO tag -->

    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/Study-Site/favicon.ico" -->

<!-- end custom head snippets -->


    <!-- MathJax for LaTeX Rendering -->
    <script type="text/javascript">
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']]
        },
        svg: {
          fontCache: 'global'
        }
      };
    </script>
    <script type="text/javascript" async
      src="https://polyfill.io/v3/polyfill.min.js?features=es6">
    </script>
    <script type="text/javascript" async
      id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>
    
  </head>

  
  <body>
    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          
            <a id="forkme_banner" href="https://github.com/XanderAP25/Study-Site">View on GitHub</a>
          

          <h1 id="project_title">Demystifying AI: A Guide to LLMs</h1>

          
          <nav class="site-nav">
  <ul class="nav">
    
      
      <li>
        <a href="/Study-Site/"
          
          >
          Home
        </a>
      </li>
      
    
      
      <li class="dropdown">
        
          <a href="/Study-Site/article_landing.html">A Guide to LLMs ▾</a>
        
        <ul class="dropdown-menu">
          
            <li>
              <a href="/Study-Site/intro_to_ai_and_llms.html"
                
                >
                Introduction to AI and LLMs
              </a>
            </li>
          
            <li>
              <a href="/Study-Site/how_llms_benefit_you_and_their_challenges.html"
                
                 class="current" >
                How LLMs Benefit You and Their Challenges
              </a>
            </li>
          
            <li>
              <a href="/Study-Site/training_and_fine_tuning_an_llm.html"
                
                >
                Training and Fine-Tuning an LLM
              </a>
            </li>
          
            <li>
              <a href="/Study-Site/making_llms_work_for_you.html"
                
                >
                Making LLMs Work for You
              </a>
            </li>
          
        </ul>
      </li>
      
    
      
      <li class="dropdown">
        
          <a href="/Study-Site/case_study.html">Case Study ▾</a>
        
        <ul class="dropdown-menu">
          
            <li>
              <a href="https://colab.research.google.com/drive/1ue50VMGv12nzZ6uQNxL6wITtvgJ0nX5V?usp=sharing"
                 target="_blank" 
                >
                Fine-Tuning a Model on Grimm's Fairy Tales
              </a>
            </li>
          
            <li>
              <a href="https://colab.research.google.com/drive/1goVTnNt6FauofB_BAQ2Db4h8uWFvfY1d?usp=sharing"
                 target="_blank" 
                >
                Generating German Fairy Tales with an LLM
              </a>
            </li>
          
            <li>
              <a href="https://colab.research.google.com/drive/1_q8NFdDmb1_QonBbXd9wk84RiPA8ei8l?usp=sharing#scrollTo=BMzdSSBlq8dq"
                 target="_blank" 
                >
                Text Analysis of Output and Grimms
              </a>
            </li>
          
        </ul>
      </li>
      
    
      
      <li class="dropdown">
        
          <a href="/Study-Site/appendix.html">Appendix ▾</a>
        
        <ul class="dropdown-menu">
          
            <li>
              <a href="/Study-Site/about.html"
                
                >
                About
              </a>
            </li>
          
            <li>
              <a href="/Study-Site/stories.html"
                
                >
                Stories
              </a>
            </li>
          
            <li>
              <a href="/Study-Site/reading_list.html"
                
                >
                Reading List
              </a>
            </li>
          
            <li>
              <a href="/Study-Site/Acknowledgements.html"
                
                >
                Acknowledgements
              </a>
            </li>
          
        </ul>
      </li>
      
    
  </ul>
</nav>
  
        </header>   
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h2 id="section-two-how-llms-benefit-you-and-their-challenges">Section Two: How LLMs Benefit You and Their Challenges</h2>

<p>At their core, LLMs process text and generate a relevant response. This is a simplified explanation of how LLMs function, but it should be clear what the potential that such a technology holds. Imagine having an assistant that can instantly summarize an article, or a peer to help brainstorm solutions to complex technical problems. What LLMs have to offer is nothing short of revolutionary, but they are not without their downsides. Like any computer program, LLMs require compute power, and lots of it. There are significant environmental concerns that we will look at later in the section that humanity must confront if we continue to use this technology. There are also many difficult ethical questions and concerns that must be addressed, or at the very least acknowledged, to not only inform your use of this technology, but to decide if AI is truly a net good.</p>

<p>For both everyday users and professionals, there is some way in which LLMs can make a tangible impact. Imagine a chatbot that can answer questions you might have on a topic of interest or study, but also help troubleshoot any tech issues you might be facing, or a proofreader that can quickly smooth out your writing. If you are considering a project of any kind, an LLM can work as a sounding board that can help identify angles of approach or ideas that you haven’t yet considered. In the professional space, management consulatants at Boston Consulting Group have been found to complete tasks 25.1% quicker with 40% better quality in their output just by adopting LLMs into their workflow (<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote" rel="footnote">1</a></sup>). Now, imagine applying that to your own workflow—writing reports, coding, or even managing emails. The potential efficiency gains could be substantial. Granted, this is just one case study for a consulting firm, and your personal philosophy on work, or your workflow, may not play as nice with AI. Yet, it still stands as an example of the power of AI when it integrates well with a userbase and workflow.</p>

<p>In education, LLMs are transforming how we teach and learn. Think about the time-consuming tasks teachers face daily: creating assessments, developing lesson plans, providing individualized feedback. LLMs have the potential to handle all of these efficiently. These tools can develop personalized learning materials like summaries, flashcards, and quizzes tailored to individual students (<sup id="fnref:6" role="doc-noteref"><a href="#fn:6" class="footnote" rel="footnote">2</a></sup>). One study on AI even makes the bold claim that LLMs can make grading more consistent and fair by reducing the subjective biases that naturally creep into human assessment (<sup id="fnref:7" role="doc-noteref"><a href="#fn:7" class="footnote" rel="footnote">3</a></sup>). There are implications here for the personal role of teachers in education, and how LLMs can potentially hamper it that should be considered before deciding if this is truly a positive change in the education space. For example, LLMs can give individualized feedback, but should they be the ones doing it instead of the human teacher? The AI can learn the quirks, failings, and proficiencies of a student, and tailor its feedback in a robust emulation of a human’s feedback, but is that worth as much as a teacher’s feedback if it is approved by them and saves them time for other teaching duties? Beyond the potential of saving time, LLMs offer powerful language support for students who may not know the native language used in the classroom. What could be most valuable is how using LLMs in classrooms now prepares students for the future AI-driven workforce. As students learn to craft effective prompts through trial and error, they’re building critical thinking skills and technological literacy that will serve them regardless of which careers emerge in our AI-integrated future.</p>

<p>The benefits of LLMs aren’t just limited to any one field or person, they’re already reshaping our world in unexpected ways. For example, in the healthcare, there have been major strides in drug discovery and molecular synthesis with AI models as the key drivers. Insilico is a biotechnology company that has previously used generative AI to develop a drug that is currently in Phase 2 clinical trials (<sup id="fnref:7:1" role="doc-noteref"><a href="#fn:7" class="footnote" rel="footnote">3</a></sup>). Although the drug was developed used generative AI rather than an LLM, their new LLM-powered system called Nach0 is capable of designing molecules, predicting their properties, and even suggesting synthesis methods (<sup id="fnref:8" role="doc-noteref"><a href="#fn:8" class="footnote" rel="footnote">4</a></sup>). While no Nach0 drugs have entered clinical trials yet, there is a possibility that the drugs of the future are designed using AI models that are built upon the LLMs you use today.</p>

<p>While there is a lot of good that LLMs can do for you and the world at large, they are clearly not a miracle technology with zero drawbacks. There is some nuance to their use, and a lot of their benefits are still in the early stages, or not fully realized yet. One of the most controversal downsides to their very existence is how their training data is obtained and used. We’ll be covering this more extensively in the following sections, but LLMs need vast amounts of data to get as competent as they’ve become today. An easy way to get this data is to scrape the entire internet. The owners and creators of digital content are typically not asked for their consent when their material is used to train AI systems, and this has led to tons of debate on the ethical and legal ramifications of training AI. Currently, there is no law against scraping data from the web and using it to train your models, but some organizations like the <em>New York Times</em>, have moved forward with lawsuits against both OpenAI and Microsoft over the use of their copyrighted content to train their models (<sup id="fnref:9" role="doc-noteref"><a href="#fn:9" class="footnote" rel="footnote">5</a></sup>). This raises an ethical dilemma: should AI companies profit from models trained on content they don’t own? Opponents, like the case <em>The New York Times’s</em> lawsuit, argue that it disregards creators’ rights and exploits their work without compensation. Proponents counter that broad data scraping is essential for AI advancement and the benefits it brings, essentially saying that accurate and higher quality outputs justify the any infringement on people’s intellectual property that may occur.</p>

<p>You might have also wondered how the broad sections of the internet are prepared for AI training. It’s not as simple as dumping raw web pages into an algorithm to train a model. Data needs to be cleaned, filtered, and categorized. Since algorithms aren’t perfect at identifying harmful or low-quality content, much of this work falls on human moderators. These workers, often from lower-income countries, are tasked with reviewing massive amounts of disturbing material containg graphic violence, hate speech, and child exploitation, all to keep AI models “safe” for users. The psychological toll of this work is severe, with many moderators reporting trauma and PTSD-like symptoms from prolonged exposure (<sup id="fnref:10" role="doc-noteref"><a href="#fn:10" class="footnote" rel="footnote">6</a></sup>). Yet, these workers remain largely invisible, underpaid, and unprotected, raising serious ethical concerns about the unseen labor behind AI advancements. The research paper “On the Dangers of Stochastic Parrots: Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency” covers many of these downsides at length, and while I will continue to draw from for covering the downsides of AI, I urge anyone with an interest in AI to read through the 10 page paper (<sup id="fnref:10:1" role="doc-noteref"><a href="#fn:10" class="footnote" rel="footnote">6</a></sup>).</p>

<p>Beyond data processing, LLMs also struggle with transparency. Most training datasets are poorly documented, making it difficult to track biases, misinformation, or potential harm (<sup id="fnref:10:2" role="doc-noteref"><a href="#fn:10" class="footnote" rel="footnote">6</a></sup>). Even today, many popular models on Hugging Face do not disclose their training data well. This lack of accountability disproportionately affects marginalized groups, as AI models trained on biased data tend to reinforce existing inequalities. From racial and gender biases in generated text to the erasure of underrepresented dialects and cultures, LLMs have the potential to reflect and amplify the flaws of the data they consume (<sup id="fnref:10:3" role="doc-noteref"><a href="#fn:10" class="footnote" rel="footnote">6</a></sup>). We’ve seen an example of the impact unchecked training data can have on an AI with the case of the Twitter chatbot Tay, which was designed to learn based on its interactions with users of the website. Within 24 hours the bot was shut down after it started spouting hateful rhetoric that it learned from the website (<sup id="fnref:15" role="doc-noteref"><a href="#fn:15" class="footnote" rel="footnote">7</a></sup>).</p>

<p>Compound the potential for bias and hatred with the environmental cost. Training and running large AI models require immense computational power, consuming as much energy as entire cities (<sup id="fnref:10:4" role="doc-noteref"><a href="#fn:10" class="footnote" rel="footnote">6</a></sup>). Even simple queries to ChatGPT consume far more energy than what is required for a Google search. As AI development accelerates, so does its carbon footprint, raising concerns about sustainability and the long-term impact on our planet. We were already facing climate challenges prior to the explosion of AI’s popularity, and regardless of the benefits they may bring, the harm they will inflict on our planet is undoubtedly one of the biggest obstacles to widespread adoption and acceptance.</p>

<p>Access to LLMs is also not universal, many people, especially in lower-income regions, are excluded from their benefits due to infrastructure limitations, language barriers, or financial costs (<sup id="fnref:10:5" role="doc-noteref"><a href="#fn:10" class="footnote" rel="footnote">6</a></sup>). Yet, these same communities often bear the brunt of AI’s environmental impact, as the energy-intensive data centers powering these models contribute to climate change and resource consumption that disproportionately affect marginalized populations (<sup id="fnref:10:6" role="doc-noteref"><a href="#fn:10" class="footnote" rel="footnote">6</a></sup>). This imbalance raises questions about who truly benefits from AI advancements and who is left dealing with the consequences.</p>

<p>AI is a revolutionary technology that can massively improve your workflow, education, and potentially lead to the rapid creation of drugs for diseases that we have not found the cure to yet, but its development has relied on ethically questionable practices, from exploitative labor to environmental harm. Anyone using it extensively should reflect on whether they’re comfortable with these trade-offs. It’s an uncomfortable but necessary conversation—one that, by acknowledging AI’s downsides, can push us toward a future where these issues are meaningfully addressed.</p>

<p style="text-align:left;">
    <a href="/Study-Site/intro_to_ai_and_llms.html" style="padding: 0.4em 0.8em; border: 1px solid #1e6bb8; color: #1e6bb8; text-decoration: none; border-radius: 3px; font-weight: bold;">← Introduction to AI and LLMs</a>
    <span style="float:right;">
        <a href="/Study-Site/training_and_fine_tuning_an_llm.html" style="padding: 0.4em 0.8em; border: 1px solid #1e6bb8; color: #1e6bb8; text-decoration: none; border-radius: 3px; font-weight: bold;">Training and Fine-Tuning an LLM →</a>
    </span>
</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:5" role="doc-endnote">
      <p>Dell’Acqua, Fabrizio, et al. “Navigating the Jagged Technological Frontier: Field Experimental Evidence of the Effects of AI on Knowledge Worker Productivity and Quality.” SSRN, 18 Sept. 2023, papers.ssrn.com/sol3/papers.cfm?abstract_id=4573321. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:6" role="doc-endnote">
      <p>Javaid, Muhammad, et al. “Unlocking the Opportunities through CHATGPT Tool towards Ameliorating the Education System.” BenchCouncil Transactions on Benchmarks, Standards and Evaluations, no. 2, 2023, p. 100115. https://doi.org/10.1016/j.tbench.2023.100115. <a href="#fnref:6" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:7" role="doc-endnote">
      <p>Alqahtani, Tariq, et al. “The Emergent Role of Artificial Intelligence, Natural Learning Processing, and Large Language Models in Higher Education and Research.” Research in Social and Administrative Pharmacy, 2023. https://doi.org/10.1016/j.sapharm.2023.05.016. <a href="#fnref:7" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:7:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
    </li>
    <li id="fn:8" role="doc-endnote">
      <p>Yao, Renee. “Quicker Cures: How Insilico Medicine Uses Generative AI to Accelerate Drug Discovery.” NVIDIA Blog, 16 Oct. 2024, blogs.nvidia.com/blog/insilico-medicine-uses-generative-ai-to-accelerate-drug-discovery/. <a href="#fnref:8" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:9" role="doc-endnote">
      <p>Michael. “The Times Sues OpenAI and Microsoft over A.I. Use of Copyrighted Work.” The New York Times, The New York Times, 27 Dec. 2023, www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html. <a href="#fnref:9" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:10" role="doc-endnote">
      <p>Bender, Emily M., et al. “On the Dangers of Stochastic Parrots: Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency.” ACM Conferences, 1 Mar. 2021, <em>dl.acm.org/doi/10.1145/3442188.3445922.</em> <a href="#fnref:10" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:10:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a> <a href="#fnref:10:2" class="reversefootnote" role="doc-backlink">&#8617;<sup>3</sup></a> <a href="#fnref:10:3" class="reversefootnote" role="doc-backlink">&#8617;<sup>4</sup></a> <a href="#fnref:10:4" class="reversefootnote" role="doc-backlink">&#8617;<sup>5</sup></a> <a href="#fnref:10:5" class="reversefootnote" role="doc-backlink">&#8617;<sup>6</sup></a> <a href="#fnref:10:6" class="reversefootnote" role="doc-backlink">&#8617;<sup>7</sup></a></p>
    </li>
    <li id="fn:15" role="doc-endnote">
      <p>“Tay (Chatbot).” Wikipedia, Wikimedia Foundation, 26 Mar. 2025, en.wikipedia.org/wiki/Tay_(chatbot). <a href="#fnref:15" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      
      <footer class="inner">
        
        <p class="copyright">Study-Site maintained by <a href="https://github.com/XanderAP25">XanderAP25</a></p>
        
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>
  </body>
</html>