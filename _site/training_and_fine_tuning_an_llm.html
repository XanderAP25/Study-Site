<!DOCTYPE html>

<html lang="en-US">

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width,maximum-scale=2">
    <link rel="stylesheet" href="/Study-Site/assets/css/styles.css">

    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Training and Fine-Tuning an LLM | A Study on LLMs</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Training and Fine-Tuning an LLM" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://localhost:4000/Study-Site/training_and_fine_tuning_an_llm.html" />
<meta property="og:url" content="http://localhost:4000/Study-Site/training_and_fine_tuning_an_llm.html" />
<meta property="og:site_name" content="A Study on LLMs" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Training and Fine-Tuning an LLM" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","headline":"Training and Fine-Tuning an LLM","url":"http://localhost:4000/Study-Site/training_and_fine_tuning_an_llm.html"}</script>
<!-- End Jekyll SEO tag -->

    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/Study-Site/favicon.ico" -->

<!-- end custom head snippets -->


    <!-- MathJax for LaTeX Rendering -->
    <script type="text/javascript">
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']]
        },
        svg: {
          fontCache: 'global'
        }
      };
    </script>
    <script type="text/javascript" async
      src="https://polyfill.io/v3/polyfill.min.js?features=es6">
    </script>
    <script type="text/javascript" async
      id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>
    
  </head>

  
  <body>
    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          
            <a id="forkme_banner" href="https://github.com/XanderAP25/Study-Site">View on GitHub</a>
          

          <h1 id="project_title">Demystifying AI: A Guide to LLMs</h1>

          
          <nav class="site-nav">
  <ul class="nav">
    
      
      <li>
        <a href="/Study-Site/"
          
          >
          Home
        </a>
      </li>
      
    
      
      <li class="dropdown">
        
          <a href="/Study-Site/article_landing.html">A Guide to LLMs ▾</a>
        
        <ul class="dropdown-menu">
          
            <li>
              <a href="/Study-Site/intro_to_ai_and_llms.html"
                
                >
                Introduction to AI and LLMs
              </a>
            </li>
          
            <li>
              <a href="/Study-Site/how_llms_can_benefit_you_and_their_challenges.html"
                
                >
                How LLMs Can Benefit You and Their Challenges
              </a>
            </li>
          
            <li>
              <a href="/Study-Site/making_llms_work_for_you.html"
                
                >
                Making LLMs Work for You
              </a>
            </li>
          
            <li>
              <a href="/Study-Site/training_and_fine_tuning_an_llm.html"
                
                 class="current" >
                Training and Fine-Tuning an LLM
              </a>
            </li>
          
            <li>
              <a href="/Study-Site/conclusion.html"
                
                >
                Conclusion
              </a>
            </li>
          
        </ul>
      </li>
      
    
      
      <li class="dropdown">
        
          <a href="/Study-Site/case_study.html">Case Study ▾</a>
        
        <ul class="dropdown-menu">
          
            <li>
              <a href="https://colab.research.google.com/drive/1ue50VMGv12nzZ6uQNxL6wITtvgJ0nX5V?usp=sharing"
                 target="_blank" 
                >
                Fine-Tuning a Model on Grimm's Fairy Tales
              </a>
            </li>
          
            <li>
              <a href="https://colab.research.google.com/drive/1goVTnNt6FauofB_BAQ2Db4h8uWFvfY1d?usp=sharing"
                 target="_blank" 
                >
                Generating German Fairy Tales with an LLM
              </a>
            </li>
          
            <li>
              <a href="https://colab.research.google.com/drive/1_q8NFdDmb1_QonBbXd9wk84RiPA8ei8l?usp=sharing#scrollTo=BMzdSSBlq8dq"
                 target="_blank" 
                >
                Text Analysis of Output and Grimms
              </a>
            </li>
          
        </ul>
      </li>
      
    
      
      <li class="dropdown">
        
          <a href="/Study-Site/appendix.html">Appendix ▾</a>
        
        <ul class="dropdown-menu">
          
            <li>
              <a href="/Study-Site/about.html"
                
                >
                About
              </a>
            </li>
          
            <li>
              <a href="/Study-Site/stories.html"
                
                >
                Stories
              </a>
            </li>
          
            <li>
              <a href="/Study-Site/reading_list.html"
                
                >
                Reading List
              </a>
            </li>
          
            <li>
              <a href="/Study-Site/Acknowledgements.html"
                
                >
                Acknowledgements
              </a>
            </li>
          
            <li>
              <a href="/Study-Site/contact_information.html"
                
                >
                Contact Information
              </a>
            </li>
          
            <li>
              <a href="/Study-Site/usage_rights.html"
                
                >
                Usage Rights
              </a>
            </li>
          
        </ul>
      </li>
      
    
  </ul>
</nav>
  
        </header>   
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h2 id="section-four-training-and-fine-tuning-an-llm">Section Four: Training and Fine-Tuning an LLM</h2>

<p>We briefly covered how models are trained in the first section, but let’s recap. During training, models process massive sequences of text, analyzing how words relate to one another within a given context. By identifying these relationships, the model learns to predict and generate coherent text based on patterns in its training data. These pre-trained LLMs are what most people will be working with when setting up their own specialized LLM, largely due to the fact that not everyone has the ability to dedicate unfathomable amounts of energy towards the LLM of their dreams. This is where in-context learning (ICL) and fine-tuning come into play.</p>

<p>Both of these techniques influence the LLM’s output, but the way each of them work is fundamentally different. Fine-tuning involves retraining the model itself on new data, altering its parameters. In-Context Learning does not require any tweaks to the parameters for the model to become specialized to whatever task you are training it for. Instead, you provide the model with examples, and it learns on the fly as you attempt to give it an education on whatever topic you are trying to specialize it for (<sup id="fnref:11" role="doc-noteref"><a href="#fn:11" class="footnote" rel="footnote">1</a></sup>). This is really useful if you want to have a model specialized for tasks such as text classification, sentiment analysis, or language translation, since you can give a bunch of examples to the AI, and have it learn how to do these tasks for you. Let’s take sentiment analysis as an example. You want to have your LLM know how to tell whether a review on a movie is positive or negative. To do this, you want to provide a set of demonstration examples for it to follow through a prompt.</p>

<table>
  <thead>
    <tr>
      <th>Prompt</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Answer the upcoming prompts using this format: <br />Review: This movie was nothing but a waste of my time and money, I’m done with this franchise. Sentiment: Negative<br />Review: The ultimate conclusion to a story five years in the making. I am speechless. Sentiment: Positive<br />Review: While the visuals and flashy fights were enough to get me through the movie, I just could not engage with the story. Sentiment: Negative</td>
    </tr>
  </tbody>
</table>

<p>That is all you need to do for a basic implementation of ICL, just give the LLM an example to follow, and it will adhere to it to the best of its abilities. Now, there are some complexities to this technique that can let you get the most out of it. Specifically, one must consider the selection of what data is used in the prompt, the format that it is presented in, and the order that it is given to the AI (<sup id="fnref:11:1" role="doc-noteref"><a href="#fn:11" class="footnote" rel="footnote">1</a></sup>). We want to provide relevant examples that are formatted in the most consumable format for the AI, and these examples should build on each other logically. Taking time to work out how you’ll educate your AI before actually carrying it out will lead to a better result. For more information on the techniques involved in maximizing In-Context Learning, I would recommend checking out <em>A Survey on In-Context Learning</em> and the numerous sources it points to for improved learning practices (<sup id="fnref:11:2" role="doc-noteref"><a href="#fn:11" class="footnote" rel="footnote">1</a></sup>).</p>

<p>You can see how I used ICL to improve an LLM’s story generation capabilities in my story generation code notebook (<sup id="fnref:15" role="doc-noteref"><a href="#fn:15" class="footnote" rel="footnote">2</a></sup>).</p>

<p>Fine-tuning is more involved than ICL, requiring modification of the model’s parameters by training it on new data that is specialized for the intended function that you want the LLM to perform. Since the LLM is being retrained, the end result is a model that can more effectively carry out the task given to it. The process of fine-tuning requires a relevant dataset. If that is a sentiment analysis model, then the input dataset could look like this:</p>

<table>
  <thead>
    <tr>
      <th>Text</th>
      <th>Sentiments</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>This movie was nothing but a waste of my time and money, I’m done with this franchise.</td>
      <td>Negative</td>
    </tr>
    <tr>
      <td>The ultimate conclusion to a story five years in the making. I am speechless.</td>
      <td>Positive</td>
    </tr>
    <tr>
      <td>While the visuals and flashy fights were enough to get me through the movie, I just could not engage with the story.</td>
      <td>Negative</td>
    </tr>
  </tbody>
</table>

<p>In a real-world application, you would want a lot more than just three reviews, but this should illustrate the type of data that is fed to models for fine-tuning.</p>

<p>From here, the model’s parameters are tweaked on the dataset, meaning that its understanding of movie review sentiment is being ingrained directly into the model. The key benefit of fine-tuning over ICL is that fine-tuning creates a more permanent integration of the new information into the LLM’s structure. Just like a person, LLMs “forget” what they learned after a session ends. Instead of having to feed an LLM the same prompt every time you want to have it learn how to do a specific task, you can finetune a model to permanently remember how to do said task.</p>

<p>You can see how I used a dataset consisting of German Fairy Tales to fine-tune an LLM in my fine-tuning code notebook (<sup id="fnref:16" role="doc-noteref"><a href="#fn:16" class="footnote" rel="footnote">3</a></sup>). If you are interested in seeing how the fine-tuned model compares to a baseline model using ICL, I recommend taking a look at my text analysis code notebook (<sup id="fnref:17" role="doc-noteref"><a href="#fn:17" class="footnote" rel="footnote">4</a></sup>). If not, then just know that fine-tuning a model in this case led to generated stories that were close in structure and themes to actual German Fairy Tales than a model using ICL, but it came at significantly higher costs to efficiency. The stories generated using ICL prompts were also not too far behind the fine-tuned model’s stories in closeness to the actual fairy tales, meaning that depending on your needs, ICL may be preferred over fine-tuning despite the loss in quality. The process of fine-tuning is quite costly, and while I touch on it in my case study notebooks, I recommend you take a look at the footnote below for more information (<sup id="fnref:18" role="doc-noteref"><a href="#fn:18" class="footnote" rel="footnote">5</a></sup>).</p>

<p style="text-align:left;">
    <a href="/Study-Site/making_llms_work_for_you.html" style="padding: 0.4em 0.8em; border: 1px solid #1e6bb8; color: #1e6bb8; text-decoration: none; border-radius: 3px; font-weight: bold;">← Making LLMs Work For You</a>
    <span style="float:right;">
        <a href="/Study-Site/conclusion.html" style="padding: 0.4em 0.8em; border: 1px solid #1e6bb8; color: #1e6bb8; text-decoration: none; border-radius: 3px; font-weight: bold;">Conclusion →</a>
    </span>
</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:11" role="doc-endnote">
      <p>Dong, Qingxiu, et al. “A Survey on In-Context Learning.” arXiv.Org, 5 Oct. 2024, arxiv.org/abs/2301.00234. <a href="#fnref:11" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:11:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a> <a href="#fnref:11:2" class="reversefootnote" role="doc-backlink">&#8617;<sup>3</sup></a></p>
    </li>
    <li id="fn:15" role="doc-endnote">
      <p><a href="https://colab.research.google.com/drive/1goVTnNt6FauofB_BAQ2Db4h8uWFvfY1d" target="_blank">Story Generation Using an LLM in a Notebook Environment</a> <a href="#fnref:15" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:16" role="doc-endnote">
      <p><a href="https://colab.research.google.com/drive/1ue50VMGv12nzZ6uQNxL6wITtvgJ0nX5V?usp=sharing" target="_blank">Finetuning an LLM on German Fairy Tales</a> <a href="#fnref:16" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:17" role="doc-endnote">
      <p><a href="https://colab.research.google.com/drive/1_q8NFdDmb1_QonBbXd9wk84RiPA8ei8l?usp=sharing#scrollTo=BMzdSSBlq8dq" target="_blank">Text Analysis of Output and Grimms</a> <a href="#fnref:17" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:18" role="doc-endnote">
      <p>LLMs use tons of VRAM, and require powerful GPUs to be used to their fullest extent. Whether that be output generation, or fine-tuning, you want to have a lot of VRAM at your disposal. You can get away with using CPUs or Apple Silicon in conjunction with your system RAM for running and fine-tuning smaller LLMs, but you will see noticeably less performance and efficiency. I mentioned this in the third section, but Google Colab is a relatively cheap resource to rent powerful GPUs that you can easily use for your AI ambitions. You can even use a free T4 GPU, which offers more power than what the layman would likely have on hand. A good rule of thumb is that you want at least 16 GB of VRAM to do anything significant with moderate sized LLMs (1-3B parameters), and you may want 80GB+ of VRAM if you’re fine-tuning larger models. <a href="#fnref:18" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      
      <footer class="inner">
        
        <p class="copyright">Study-Site maintained by <a href="https://github.com/XanderAP25">XanderAP25</a></p>
        
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>
  </body>
</html>