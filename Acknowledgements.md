---
layout: default
title: Acknowledgements
---

## Acknowledgements

This study would not have been possible without the support of the wonderful **CIS Department** at *Washington & Jefferson College*, who provided both the opportunity and the skills necessary to carry it out. In particular, I would like to extend my deepest thanks to **Dr. Ladd** and **Dr. Holland-Minkley** for their guidance throughout all stages of this project.

Dr. Ladd served as my project advisor and offered constant mentorship and support throughout the semester. He undertook the arduous task of reviewing and critiquing the very first (and very rough) draft of the *Guide to LLMs*. There are truly not enough words to express how helpful and encouraging he was at every stage of this project.

Dr. Holland-Minkley, my academic advisor, played a pivotal role in the initial planning and conceptualization of this independent study. She helped me shape the foundation for what eventually became what you are seeing today. Her feedback on my article drafts, code notebooks, and this website was instrumental in refining and strengthening the final product.

To both of them, thank you.

### Tools, Libraries, and Resources Used

This project drew on a broad range of tools, libraries, datasets, and platforms for research, experimentation, analysis, and presentation. Key resources include:

#### Development and Hosting
- **Google Colab** — primary IDE for executing Python code and machine learning workflows.
- **Jekyll** — static site generator used to build the website.
- **GitHub Pages** — for version control and website hosting.
- **Slate Theme** ([GitHub Repository](https://github.com/pages-themes/slate)) — Jekyll theme used for site design.

#### Datasets and Models
- **Grimm's Fairy Tales Dataset** ([Kaggle Dataset](https://www.kaggle.com/datasets/tschomacker/grimms-fairy-tales)) — corpus used for in-context learning, fine-tuning, and comparative text analysis.
- **Mistral-7B Instruct v0.3** ([Hugging Face Model](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3)) — language model used for fine-tuning and text generation.

#### Machine Learning and Text Analysis Libraries
- **Hugging Face Transformers** — for accessing and fine-tuning language models.
- **Torch** — backend framework supporting model training and inference.
- **Unsloth** — for optimizing and accelerating fine-tuning.
- **Pandas** — for data cleaning and manipulation.
- **Scikit-learn** — for statistical analysis and text evaluation.
- **SpaCy** — for linguistic feature extraction and word-level analysis.
- **Seaborn** and **Matplotlib** — for data visualization of text analysis results.
- **Fighting Words Toolkit** ([GitHub Repository](https://github.com/jmhessel/FightingWords)) — for comparative word choice analysis between generated and original texts.



These resources, alongside numerous open-source libraries and frameworks, made the research, experimentation, and presentation of this project possible.

